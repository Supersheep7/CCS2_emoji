Done:

1. Choose and collect 50-100 Emojis from tops 
2. Choose twitter dataset to work with
3. Filter dataset for those 50-100 emojis -> Get data
4. Single dataframe, started some analysis on how much emojis are there etc

===

To do:

16/05

1. Sanitize the data
2. Work on data, various
3. Commit to a first selection of emojis

18/05

3. Run model for extracting embeddings on data. Maybe we will have to augment the data or smth. 
4. Get embeddings of 50-100 emojis 

19/05

5. Get encodings of 50-100 emojis from a (pre-trained?) autoencoder -> Maybe we will need to compress them to a PCA?

20/05

6. Fuse the two representation in some relevant way

21/05

7. Collect distances for (N*N-1)/2 pairs of emojis
8. Select 50 relevant pairs of emojis to test against gold data

22/05

9. Design experiment: methods
10. Design experiment: sample bias analysis

23-26/05 (switch to NLP and AIMAS videos)

11. Run experiment

27/05

12. Test pairs of emojis, distances of each model against gold

28-2/05

13. Plots, tables, results
14. Write report